{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d380c59",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "843dcdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1244184 entries, 0 to 1244183\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count    Dtype \n",
      "---  ------         --------------    ----- \n",
      " 0   publish_date   1244184 non-null  int64 \n",
      " 1   headline_text  1244184 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 19.0+ MB\n",
      "None\n",
      "   publish_date                                      headline_text\n",
      "0      20030219  aba decides against community broadcasting lic...\n",
      "1      20030219     act fire witnesses must be aware of defamation\n",
      "2      20030219     a g calls for infrastructure protection summit\n",
      "3      20030219           air nz staff in aust strike for pay rise\n",
      "4      20030219      air nz strike to affect australian travellers\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (make sure to replace 'path/to/million-headlines.csv' with the actual path to your dataset)\n",
    "df = pd.read_csv(\"C:/Users/pater/OneDrive/Documents/Code Practice/Natural Language Processing/abcnews-date-text.csv\")\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(df.info())\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b677f6d",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26ee90f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-Words Representation:\n",
      "[[1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
      " [0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 0]]\n",
      "Feature Names (Vocabulary):\n",
      "['aba' 'act' 'against' 'air' 'aust' 'aware' 'be' 'broadcasting' 'calls'\n",
      " 'community' 'decides' 'defamation' 'fire' 'for' 'in' 'infrastructure'\n",
      " 'licence' 'must' 'nz' 'of' 'pay' 'protection' 'rise' 'staff' 'strike'\n",
      " 'summit' 'witnesses']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample input text\n",
    "input_text = ['aba decides against community broadcasting licence', 'act fire witnesses must be aware of defamation', 'a g calls for infrastructure protection summit', 'air nz staff in aust strike for pay rise']\n",
    "\n",
    "# Create a CountVectorizer instance\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the input text\n",
    "bow_representation = vectorizer.fit_transform(input_text)\n",
    "\n",
    "# Get the feature names (words in the vocabulary)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Display the BoW representation\n",
    "print(\"Bag-of-Words Representation:\")\n",
    "print(bow_representation.toarray())\n",
    "print(\"Feature Names (Vocabulary):\")\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5981e76c",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db006db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Representation:\n",
      "[[0.40824829 0.         0.40824829 0.         0.         0.\n",
      "  0.         0.40824829 0.         0.40824829 0.40824829 0.\n",
      "  0.         0.         0.         0.         0.40824829 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.35355339 0.         0.         0.         0.35355339\n",
      "  0.35355339 0.         0.         0.         0.         0.35355339\n",
      "  0.35355339 0.         0.         0.         0.         0.35355339\n",
      "  0.         0.35355339 0.         0.         0.         0.\n",
      "  0.         0.         0.35355339]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.46516193 0.         0.         0.\n",
      "  0.         0.36673901 0.         0.46516193 0.         0.\n",
      "  0.         0.         0.         0.46516193 0.         0.\n",
      "  0.         0.46516193 0.        ]\n",
      " [0.         0.         0.         0.34056989 0.34056989 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.26850921 0.34056989 0.         0.         0.\n",
      "  0.34056989 0.         0.34056989 0.         0.34056989 0.34056989\n",
      "  0.34056989 0.         0.        ]]\n",
      "Feature Names (Vocabulary):\n",
      "['aba' 'act' 'against' 'air' 'aust' 'aware' 'be' 'broadcasting' 'calls'\n",
      " 'community' 'decides' 'defamation' 'fire' 'for' 'in' 'infrastructure'\n",
      " 'licence' 'must' 'nz' 'of' 'pay' 'protection' 'rise' 'staff' 'strike'\n",
      " 'summit' 'witnesses']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample input text\n",
    "input_text = ['aba decides against community broadcasting licence', 'act fire witnesses must be aware of defamation', 'a g calls for infrastructure protection summit', 'air nz staff in aust strike for pay rise']\n",
    "\n",
    "# Create a TfidfVectorizer instance\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the input text\n",
    "tfidf_representation = tfidf_vectorizer.fit_transform(input_text)\n",
    "\n",
    "# Get the feature names (words in the vocabulary)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Display the TF-IDF representation\n",
    "print(\"TF-IDF Representation:\")\n",
    "print(tfidf_representation.toarray())\n",
    "print(\"Feature Names (Vocabulary):\")\n",
    "print(feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c723ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42805778",
   "metadata": {},
   "source": [
    "# N- Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df7d4eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Representation:\n",
      "[[1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 0\n",
      "  0 1 1 0 0 0 0 0 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0\n",
      "  0 0 0 0 0 1 1 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 1\n",
      "  1 0 0 1 1 0 0 1 1 1 1 1 0 0 0]]\n",
      "Feature Names (Bigrams):\n",
      "['aba' 'aba decides' 'act' 'act fire' 'against' 'against community' 'air'\n",
      " 'air nz' 'aust' 'aust strike' 'aware' 'aware of' 'be' 'be aware'\n",
      " 'broadcasting' 'broadcasting licence' 'calls' 'calls for' 'community'\n",
      " 'community broadcasting' 'decides' 'decides against' 'defamation' 'fire'\n",
      " 'fire witnesses' 'for' 'for infrastructure' 'for pay' 'in' 'in aust'\n",
      " 'infrastructure' 'infrastructure protection' 'licence' 'must' 'must be'\n",
      " 'nz' 'nz staff' 'of' 'of defamation' 'pay' 'pay rise' 'protection'\n",
      " 'protection summit' 'rise' 'staff' 'staff in' 'strike' 'strike for'\n",
      " 'summit' 'witnesses' 'witnesses must']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample input text\n",
    "input_text = ['aba decides against community broadcasting licence', 'act fire witnesses must be aware of defamation', 'a g calls for infrastructure protection summit', 'air nz staff in aust strike for pay rise']\n",
    "\n",
    "# Create a CountVectorizer instance for bigrams\n",
    "ngram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "# Fit and transform the input text\n",
    "ngram_representation = ngram_vectorizer.fit_transform(input_text)\n",
    "\n",
    "# Get the feature names (bigrams in the vocabulary)\n",
    "feature_names = ngram_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Display the bigram representation\n",
    "print(\"Bigram Representation:\")\n",
    "print(ngram_representation.toarray())\n",
    "print(\"Feature Names (Bigrams):\")\n",
    "print(feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ae41583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Representation:\n",
      "[[1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 1 0]]\n",
      "Feature Names (Bigrams):\n",
      "['aba decides' 'act fire' 'against community' 'air nz' 'aust strike'\n",
      " 'aware of' 'be aware' 'broadcasting licence' 'calls for'\n",
      " 'community broadcasting' 'decides against' 'fire witnesses'\n",
      " 'for infrastructure' 'for pay' 'in aust' 'infrastructure protection'\n",
      " 'must be' 'nz staff' 'of defamation' 'pay rise' 'protection summit'\n",
      " 'staff in' 'strike for' 'witnesses must']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample input text\n",
    "input_text = ['aba decides against community broadcasting licence', 'act fire witnesses must be aware of defamation', 'a g calls for infrastructure protection summit', 'air nz staff in aust strike for pay rise']\n",
    "\n",
    "# Create a CountVectorizer instance for bigrams\n",
    "ngram_vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "\n",
    "# Fit and transform the input text\n",
    "ngram_representation = ngram_vectorizer.fit_transform(input_text)\n",
    "\n",
    "# Get the feature names (bigrams in the vocabulary)\n",
    "feature_names = ngram_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Display the bigram representation\n",
    "print(\"Bigram Representation:\")\n",
    "print(ngram_representation.toarray())\n",
    "print(\"Feature Names (Bigrams):\")\n",
    "print(feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc19fef4",
   "metadata": {},
   "source": [
    "# One-Hot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f99f02dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot Encoding Representation:\n",
      "[[1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
      " [0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 0]]\n",
      "Feature Names (Vocabulary):\n",
      "['aba' 'act' 'against' 'air' 'aust' 'aware' 'be' 'broadcasting' 'calls'\n",
      " 'community' 'decides' 'defamation' 'fire' 'for' 'in' 'infrastructure'\n",
      " 'licence' 'must' 'nz' 'of' 'pay' 'protection' 'rise' 'staff' 'strike'\n",
      " 'summit' 'witnesses']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample input text\n",
    "input_text = ['aba decides against community broadcasting licence', 'act fire witnesses must be aware of defamation', 'a g calls for infrastructure protection summit', 'air nz staff in aust strike for pay rise']\n",
    "\n",
    "# Create a CountVectorizer instance for One-Hot Encoding\n",
    "one_hot_vectorizer = CountVectorizer(binary=True)\n",
    "\n",
    "# Fit and transform the input text\n",
    "one_hot_representation = one_hot_vectorizer.fit_transform(input_text)\n",
    "\n",
    "# Get the feature names (words in the vocabulary)\n",
    "feature_names = one_hot_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Display the One-Hot Encoding representation\n",
    "print(\"One-Hot Encoding Representation:\")\n",
    "print(one_hot_representation.toarray())\n",
    "print(\"Feature Names (Vocabulary):\")\n",
    "print(feature_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
